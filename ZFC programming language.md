# ZFC programming language

all numbers are created equal, but sum are more equal than others

liskov substitution principle == turing completeness, turing universality, turing equivalence are all satisfied

the logarithmic leap was the transistor: the conditional branch - it's a + bias, - bias, or no bias
branching function specifices complexity
e^(number of times it branches)

but this is too abstracted in code, it's more complicated - it should just be lambda calculus
halting problem is a ????? myabe - i.e. like print butts if the 10 millionth digit of pi is 7
it should be a defined equality (that you can evaluate with uncertainty, so like checking that the contents of two 1GB files are the same; if you've found no errors or deviations so far, from Gaussian statistics, you can predict the chance that they are indeed the same - purely from entropy (and inferrered from knowladge of previous operations on the data))

unit test that on all dependencies and ur fine

# aasimov #-1 don't do anything unless you're sure of the consequences and they are well defined (i.e. purely functional, no state modification, don't modify globvars just envvars) so the only thing you have to worry about is quantum tunelling/quantum vacuum fluctuations. or background radiation. no fear of skynet

# INFORMATION AS A DIMENSION? (it's a projection but a useful one)

"The fundamental problem of communication is that of reproducing at one point, either exactly or approximately, a message selected at another point." - Shannon

well clearly this problem is solved, its a git repo! and git clone. git add state/* 
do lambda calculus on a state to find out what's changed


- fundamental uncertainty QM


The entropy, H, of a discrete random variable X is a measure of the amount of uncertainty associated with the value of X.

this is the fundamental quantity

the strings are the dimensions, but theyre just quantum numbers

Joint entropy of (X,Y)

start off modelling an infinite square well

kinetic energy and momentum

mutual information - amount of info that can be obtained about one random variable by observing another

### SINGULARITIES AND ASYMPTOTES OF REALITY - MANIFOLDS

e = mc^2

ML^2 T^-2 = (M) (L-1 T-1)^2

this is a vector cross product

mass scalar, time vector, length vector, quanta = planck length/time/mass ? but if mass is a scalar...
mass is more fundaental ?

because the most fundamental thing is the empty set

ordinality - 

continued reimann sums: -1/12 its gonna be an e^-( ordinal vector vector ^ n dimensions thing)

reality is clearly fractals - recursive sums of e * some quantum numbers and pi * some other quantum numbers ln( one of them numbers ) * dimensions sin (e pi i ) functions just iterated 

# HERE'S THE GROUNBREAKING MATH BIT
### so basically

we have:
	- constants:
		- _e_,
		- _i_,
		- _pi_,
	- constants == model in MVC pattern
	- ternary choices. e for order/chaos, pi for beauty/repetition/ritual/curvature/different perspectives/phase, and i for complexity (a superposition of both of them)

we have: {} empty set which implies ordinality and cardinality - view (buckets, projections, slices)
we have functions: sine: periodicity logarithm: order and anti-order (cosin), and anti-order, chaos: (exp)
theories as monads - chains of functions, so you can define pretty much any math thing in terms of a chain of these - unions of sets or the number of elements of sets (from ordinal/cardinal)
we have: zfc axioms - controller, all of which boils down to the axiom of choice - free will, essentially, and the free will is in the controller?

ordinal stack /cardinal heap
stack overflow and heap failures are diferent things - different analogies

### Euler's Identity (and formula):
Euler's formula is ubiquitous in mathematics, physics, and engineering. The physicist Richard Feynman called the equation "our jewel" and "the most remarkable formula in mathematics."

hmmmery... lets have a look at it:

this relates cos, and anti cos (repeated exponention of i leads to inverse since i^2 = -1 ) 

this relates log and anti-log = it's exponents and 

hashign functions as do anti-order (artificial complexity)

time as a binomial function - minkowski spacetime cone in dimensions of ct = planck time; 

bernoulli numbers: 


### interesting paralells:
cool stuff:
	- logarithmic advances in human technology. advancing towards singularity: order
	- _*OOOH** MAYBE YOU DON'T EVEN NEED E I OR PI - they all have continued sum representations, which is, yep, you guessed it: a monad. cool huh
	- reimann sums are just hella weird monads and guess what they also generate fractals right?
	- 1/e^(-1/12i^3) or something
	- linear relations are usually jsut a continued sum - this is why calculus does actually work, after all the underlying dimensionality is there
	- same with stephen wolfram's a new kind of science - those hella cool pictures of stuff generating and dying out with repeated sums, they parallel nature and some of them lead to complexity, exactly because that's all math is, just a bunch of these same rules done repeatedly -- see below
	- to be honest you could probably define sin and cos as repeated sums too - oh wait yeah division of two scalars = sin something (in rads, which is why you use rads)
	- this probably implies orthogonalighty - ie. right angles as a thing are important. same with cuves. same with the golden ratio. its the same just cool repeated sums that are nice because the numbers are nice. so i guess if we just modelled reality it might all be continued sums of the perfect ratio (0.61803398875), - inverse fibbonaci
	- now the way reality seems to have evolved is just energetically favourable configurations of these dimensiony things. so what stephen wolfram did doing the iterative sequencies and found that some died out quick, but some became complex, and some became periodical


derived things:
- euler's formula is probably acutally really helpful here since those are the 3 fundamental things

- reality is probably just a combination of the dimensions of eulers formula? (i.e. ordinality, cardinality of each element), then the combinations thereof all line up nicely and when its a nice energetically favourable config then it sticks about. sometimes it does some crazy weird stuff for a bit then goes periodical or constant. sometimes it asymptotes. but other than that there's not much else

- energetically favourable situtations are nash equilibria. 99% of the time they're a local minimum and not actually 

- other things are gonna be chains of differential calculus and weird orders of iterated ln sin functions etc

- we can proabbly just steal some mathematica source code and hilariously metaprogram this with some templates (projection operator matrixy thing) to predict what reality's doing (and also if it differs then we may be wrong (also i might suck at programming))

- algorithms are also monads too. since they are functions. implementations in programming, even OO are an abstraction this is why implementing an algo isn't as easy as "give me a web and a binary tree" unless you're in go maybe but they haven't made the full quantum leap

- schizophrenia is when the exponentials stack up way too much in your brain chemistry and bad things happen (yea i'm watching a beautiful mind on screen 2 of 3 while writing this lol)
- CRUD (create read update destroy) - database pattern - is just chained set operations, bisecting, unions or whatever
- also plato was right everything is geometry lol. chained configurations, trig, log, etc 

- oh god maybe its all reimann manifolds and manifolds of fundamental forces ? the manifold and topology is the monad structure, the geometry and configuration is the dimensionality (i.e. the chained functions of operations on the empty set all the way upwards).

- yeah same with crypto - its supposed to be hard and complicated, its just a hash of state variables - i.e. yep, you got it yet another complicated manifold. so lol we could plot a fractal for SHA hashing or MD5 or something and see what they look like!

- huh depenency inversion, to model a reality, just take the inverse of all the chained functions, and plot a graph of it, i.e. lambda calculus on whatever your thing is. 
		- so like a shaded 1/x plot graph -> x or something?
			- idk. but the idea here is fractals are an inversion projection of these really complicated monads into the input variables in euclidian space.
				- which almost implies beauty is an elegant connection to the past and whatever insight that shows
					- hindsight is 20:20 but interpreting it contextually is hard, the harder time goes on (like me understanding wtf its like in the 1500s is clearly not gonna happen no matter how much wikipedia i read)
	- intelligence is an elegant theory of the future 

- so i guess aspects of the topology - whether each of the 

quantum mechanics formulation:
	-
	

this defines basically all of euclidian space, quantum mechanics, maths, infinity, reimann sums, vector spaces, fuck it you name it this is in here






    XP
   / \
spec  X'
     / \
    X'  adjunct
   / \
  X   complement
  |
head

  	 NP
    /  \
  Det  N'
   |   |
  the  N
       |
      cat


# Kullback–Leibler divergence (information gain)

[example experiment](http://upload.wikimedia.org/math/8/e/7/8e7c3b0f381df46720176d46d72d6160.png "Example ex[eriment")

information theory of bernoulli trial/bernoulli scheme

test: countable direct product -> observable operator -> projection
base space -> observer hilbert space

apply to [meausure (math theory)](http://en.wikipedia.org/wiki/Measure_space#measure_space) all sets: R^n dimensions of space

Technically, a measure is a function that assigns a non-negative real number or +∞ to (certain) subsets of a set X (see Definition below). It must assign 0 to the empty set and be (countably) additive: the measure of a 'large' subset that can be decomposed into a finite (or countable) number of 'smaller' disjoint subsets, is the sum of the measures of the "smaller" subsets. In general, if one wants to associate a consistent size to each subset of a given set while satisfying the other axioms of a measure, one only finds trivial examples like the counting measure. This problem was resolved by defining measure only on a sub-collection of all subsets; the so-called measurable subsets, which are required to form a σ-algebra. This means that countable unions, countable intersections and complements of measurable subsets are measurable. Non-measurable sets in a Euclidean space, on which the Lebesgue measure cannot be defined consistently, are necessarily complicated in the sense of being badly mixed up with their complement. Indeed, their existence is a non-trivial consequence of the axiom of choice

###### The Simplest observable:
```python
def measure(object):
	return ['']
```

###### The simplest object, a set (a null pointer):
```python
Class FundamentalObject(type, dimensions, R^n, bitmask):
	def __init(self)__:
	# so 0 = fundamental particles, 1 = fermions, bosons, etc
	# init is just a recursive thing on the bitmask until you head down the set-inheretance heirarchy
		return ['']
```

###### Axioms - write in functional code and then that's the back of this problem broken. this is a final, virtual class - it's not implementation specific at all. axioms are independant of situation

#### SOLID -> MATH

### STRONG/WEAK forces -> strong/weak typing inheretance is gravity?


enum FundamentalTypes:
{
	empty set
}

from [wolfram math world](http://mathworld.wolfram.com/Measure.html): 

>	A measure is defined as a nonnegative real function from a delta-ring F such that
>
>	 m(emptyset)=0, 	
>	(1)
>	where emptyset is the empty set, and
>
>	 m(A)=sum_(n)m(A_n) 	
>	(2)
>	for any finite or countable collection of pairwise disjoint sets (A_n) in F such that A= union A_n is also in F.

this is the most basic observation. stuff is hard b/c its badly mixed up wtih complement? yes, this is because of you being wron  and applying the axiom of choice to ur measurement space in an invalid way - idk like the ether idea of photons or whatever. 

this ALSO aplies to our objects, as they are, after all objects that play by the same rules - except their "self" is the computer

Noether's theorem

ergodic theory, - peturbation of dynamical systems: sin, ln, exp, x^n, complex

entropy -> p ln p units -> (shannon) -> information, order
sin -> (t,) (t,x) // consts wavenumber and http://mathworld.wolfram.com/WaveEquation.html periodic pertubations (dt = planck time)
e^ -> anti-entropy -> also inheretance -> erdos number -> chaos
x^n -> euclidian - just spatial constraints 
complex - weird time - relativity (special/gen->em/strong)

this dimensional analysis applied to core phys F = ma, schroedinger, E= mc^2

nabla, dalembertian,

PDEs, ODEs,

figure out the risomatic aspec of the axioms

to destroy an object, divide its pointer by zero

curious, good starting potentials, persisitent, lucky

do this the lazy way - wolfram - those functions grep each variable print dimensions and name

template interactions - strong/weak/grav/em
compare dimentions (strong has color charge, is weird) (weak h)

superpositions and intersections of the dimensional orders
meta-mathematics

(if u wanna recursively do this based on scipy libs you could i guess)

imperative programming: alalogous to rituals - u dont rly know what ur doin


##### Back to computer concepts:
IO - communication: parallel/serial concurrent/... not 


kernel is math
user space is commands in english

****


Concepts:
Generative grammar, constant recursion, start off from very basic knowns, dE, dp, hbar, and a certainty related to that? shannon unit? start off from thought experiments

define asimov early on lol. u wanna be safe. also don't instantly hook it up to wikipedia and see what it does do that in a lame duck debug mode lol, thats what skynet taught us.

add ZFC mathematical axioms into the generative grammar and you have the foundations of maths

make your generative grammar easy to use and incorporate this into object oriented programming

stack for more known stuff, heap for less well known stuff - strong/weak

all data is atomic (after all information is just fundamental particles and quantum numbers)

start-up routine should inherently imply +, -, + + = * (iterative addition) from the rules of ZFC + set theory

start off with the empty set object, and self

self for the computer is just its environment but the concept extends to any relative observer (an observer at a given point in minkowski spacetime?)

all events are inherently lorentz transformed (but not much)
dispersion operators on the total entropy of the information field

continous integration, constant verification - blockchain


###### BRINGING IT BACK TO PROGRAMS

well this is all just matrix operations, really

you start with an 0x0 matrix, and can copy it, unison it, project members etc (ASM)

-> use those to build up universal operators
-> use those to build up functions ; 
-> use those to build up theories based on topology of functions
-> use those to build unifying theories based on manifolds 
-> recursive GUT tree of inheritance - run the possible entire list of possible computable things vs defining the procedures

-> all objects are monads which are just pointers and a value - stack is known or predictable, heap is unknown

-> fermions = static with state variables - i.e. if it exists, E > h_bar/2 - (pauli, only one instance), bosons are not static

_ you have a null pointer
__ what do you want to do?
---see what's at the pointer (random data/HEAP) (zeros/deliberate: Stack)
--- mess with the pointer (log = bitshift)

notes
========
### concepts: 
Generative grammar, recursion

start off with one bit of order and one bit of uncertainty

a wierd quote:
- "it is only in the mysterious equations of love that any logical reasons can be found" from the popular motion picture [a beautiful mind](http://www.imdb.com/title/tt0268978/) - which is interesting because pair this with the [greek concepts of love](http://en.wikipedia.org/wiki/Greek_words_for_love):
	- agape - spiritual love
	- eros - phyiscal passionate love
	- philia - mental love
	- storge - affection, natural affection

	hmm. lets dig in a bit

- now this is going to sound like the ramblings of a lunatic (surely you're joking mr jp) - but i reckon these divisions kinda sorta reflect the four fundamental forces (doesn't really matter how well they correlate, just that they vaguely do)
	- photons as "information" "energy" "quantum background" -> philia is wanting to absorb energy or information
	- gluons from the strong force - "force mediators" - very strong attraction at short ranges (u gotta be close already otherwise its never gonna happen) 


	(idk about the 4 constants yet but i'll get to that, its probably again a chain of em) 

flashed up on the titles at the end of the film - nash's theorems influenced (a load of capitalist shit fuck that his math was way awesomer than "influencing global trade negotitions" and "national labor relations", what a load of crap, his many varied theories were infinitely more elegant and insightful than to be reduced to that shit. but anyway) - break throughs in evolutionary biology. oh guess what that's exactly what we're talking about here. everything is evolutionary biology. logarithmic expansion is just when we're solving sets of problems - taming the chaos, by reducing the + entropy (the ai factor in ordinals i guess?) biology is just the study of a cohesive organic system (a massive amount of chemistry all layered up really complicatedly); chemistry is the study of the molecules/chemicals etc - sets of complex arrangements of particles and their interactions, the dyanmics of those systems: modelled very accurately by physics of the outer atom (which is why we had advances in chemistry )

### asimov laws (use in prod lol!!!) (disable in debug)

### what are our fundamental i am a thing
things have energy and momentum 
we exist in 3 dimensions of space (x,y,z) and one of time

equality identicality
operators on information - ban 
factor in favour of h - logarithmic potential vector of h

switch base easily

degree of beleif in a hypothesis - turing

what do i look like from the point of view of ? (self, others, state, potentials, specific areas etc as well as projections)


degrees of freedom and dimensions as opposed to numbers - define a hilbert space and manifold to work in 

plus minus infinity, undefined (1/0) -> null divide by zero to kill

+ to create
- to remove

symmetry laws STRONG/WEAK strong - owned, physically known, certain, hashed, secure, weak - external.
functional programming for strong inputs, weak use imperative programming

environment variables - physical constants

scalar -> vector -> 

one time pad on boot up for security purposes - huh you don't need cryptographic hardness, neat

### language grammars

GRAMMARS
- imperfect tense - referring to previous state - unfinished
- present tense - now - current instruction pointer + state
- present imperative - let x = y
- "[optative mood](http://en.wikipedia.org/wiki/Optative_mood)" /tense
- retrospective? 

### starting point: how would a human do this?

hello, world
in/out

i think, thererfore i am, but i don't know what that is (hbar or whatever, dE, dp)

there is a world around me, i think i can see, hear, feel,

a "problem" "hypothesis" 

what else could i [verb]

i do not know what i am

what am i doing? (runnning proceses) 

where am i (start off at home)

senses?

what is important about?

we think x [is/isn't/tentative]  // tentative and y/n combine? or its a spectrum of certainty? YES

i think [there is] - create a thing

what does x look like [then/now/in the future]

who can i talk to?

say hello to my friend:

what can i go and see?

copy

git commands?